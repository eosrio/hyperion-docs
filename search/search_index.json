{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hyperion History API Scalable Full History API Solution for EOSIO based blockchains Made with \u2665 by EOS Rio 1. Overview Hyperion is a full history solution for indexing, storing and retrieving EOSIO blockchain`s historical data. EOSIO protocol is highly scalable reaching up to tens of thousands of transactions per second demanding high performance indexing and optimized storage and querying solutions. Hyperion is developed to tackle those challenges providing open source software to be operated by block producers, infrastructure providers and dApp developers. Focused on delivering faster search times, lower bandwidth overhead and easier usability for UI/UX developers, Hyperion implements an improved data structure actions are stored in a flattened format a parent field is added to the inline actions to point to the parent global sequence if the inline action data is identical to the parent it is considered a notification and thus removed from the database no blocks or transaction data is stored, all information can be reconstructed from actions 2. Architecture The following components are required in order to have a fully functional Hyperion API deployment, for small use cases its fine to run all components on a single machine. But for larger chains and production environments we recommend setting them up into different servers under a high-speed local network. 2.1 - Elasticsearch Cluster The ES cluster is responsible for storing all indexed data. Direct access to the Hyperion API and Indexer must be provided. We recommend nodes in the cluster to have at least 32GB of RAM and 8 cpu cores. SSD/NVME drives are recommended for maximum indexing throughput. For production environments a multi-node cluster is highly recommended. 2.2 - Hyperion Indexer The Indexer is a Node.js based app that process data from the state history plugin and allows it to be indexed. The PM2 process manager is used to launch and operate the indexer. The configuration flexibility is very extensive, so system recommendations will depend on the use case and data load. It will require access to at least one ES node, RabbitMQ and the state history node. 2.3 - Hyperion API Parallelizable API server that provides the V2 and V1 (legacy history plugin) endpoints. It is launched by PM2 and can also operate in cluster mode. It requires direct access to at least one ES node for the queries and all other services for full healthcheck 2.4 - RabbitMQ Use as messaging queue and data transport between the indexer stages 2.5 - EOSIO State History Nodeos plugin used to collect action traces and state deltas. Provides data via websocket to the indexer 3. How to use 3.1 For Providers For providers, click here 3.2 For Developers For developers, click here","title":"Home"},{"location":"#hyperion-history-api","text":"Scalable Full History API Solution for EOSIO based blockchains Made with \u2665 by EOS Rio","title":"Hyperion History API"},{"location":"#1-overview","text":"Hyperion is a full history solution for indexing, storing and retrieving EOSIO blockchain`s historical data. EOSIO protocol is highly scalable reaching up to tens of thousands of transactions per second demanding high performance indexing and optimized storage and querying solutions. Hyperion is developed to tackle those challenges providing open source software to be operated by block producers, infrastructure providers and dApp developers. Focused on delivering faster search times, lower bandwidth overhead and easier usability for UI/UX developers, Hyperion implements an improved data structure actions are stored in a flattened format a parent field is added to the inline actions to point to the parent global sequence if the inline action data is identical to the parent it is considered a notification and thus removed from the database no blocks or transaction data is stored, all information can be reconstructed from actions","title":"1. Overview"},{"location":"#2-architecture","text":"The following components are required in order to have a fully functional Hyperion API deployment, for small use cases its fine to run all components on a single machine. But for larger chains and production environments we recommend setting them up into different servers under a high-speed local network.","title":"2. Architecture"},{"location":"#21-elasticsearch-cluster","text":"The ES cluster is responsible for storing all indexed data. Direct access to the Hyperion API and Indexer must be provided. We recommend nodes in the cluster to have at least 32GB of RAM and 8 cpu cores. SSD/NVME drives are recommended for maximum indexing throughput. For production environments a multi-node cluster is highly recommended.","title":"2.1 - Elasticsearch Cluster"},{"location":"#22-hyperion-indexer","text":"The Indexer is a Node.js based app that process data from the state history plugin and allows it to be indexed. The PM2 process manager is used to launch and operate the indexer. The configuration flexibility is very extensive, so system recommendations will depend on the use case and data load. It will require access to at least one ES node, RabbitMQ and the state history node.","title":"2.2 - Hyperion Indexer"},{"location":"#23-hyperion-api","text":"Parallelizable API server that provides the V2 and V1 (legacy history plugin) endpoints. It is launched by PM2 and can also operate in cluster mode. It requires direct access to at least one ES node for the queries and all other services for full healthcheck","title":"2.3 - Hyperion API"},{"location":"#24-rabbitmq","text":"Use as messaging queue and data transport between the indexer stages","title":"2.4 - RabbitMQ"},{"location":"#25-eosio-state-history","text":"Nodeos plugin used to collect action traces and state deltas. Provides data via websocket to the indexer","title":"2.5 - EOSIO State History"},{"location":"#3-how-to-use","text":"","title":"3. How to use"},{"location":"#31-for-providers","text":"For providers, click here","title":"3.1 For Providers"},{"location":"#32-for-developers","text":"For developers, click here","title":"3.2 For Developers"},{"location":"chain/","text":"Detailed description of the chains/example.config.json { api :{ -- API configuration chain_name : EXAMPLE Chain , server_addr : 127.0.0.1 , server_port :7000, server_name : 127.0.0.1:7000 , provider_name : Example Provider , provider_url : https://example.com , chain_logo_url : , enable_caching :true, -- Set API cache cache_life :1, -- Define the cache life limits :{ -- Setting API response limits get_actions :1000, get_voters :100, get_links :1000, get_deltas :1000 }, access_log :false, enable_explorer :false }, settings :{ preview :false, - Preview mode - prints worker map and exit chain : eos , -- Chain named (The same used on ecosystem.config.js) eosio_alias : eosio , parser : 1.8 , -- Version of the parser to be used auto_stop :300, -- Automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) index_version : v1 , -- Set the index version debug :false, -- Set the debug mode rate_monitoring :true, bp_logs :false, -- Enable logs bp_monitoring :false, ipc_debug_rate :2000 }, blacklists :{ -- blacklist for actions and deltas actions :[ ], deltas :[ ] }, whitelists :{ -- whitelist for actions and deltas actions :[ ], deltas :[ ] }, scaling :{ -- Scalling options: batch_size :10000, -- Parallel reader batch size in blocks queue_limit :50000, -- Queue size limit on rabbitmq readers :1, -- Number of readers ds_queues :1, -- Number of deserializer queues ds_threads :1, -- Number of deserializer threads ds_pool_size :1, -- Deserializer pool size indexing_queues :1, -- Number of indexing queues ad_idx_queues :1, -- Multiplier for action indexing queues max_autoscale :4, -- Max number of readers to autoscale auto_scale_trigger :20000 -- Number of itens on queue to trigger autoscale }, indexer :{ -- Indexer configuration start_on :0, -- Start indexing on block (0=disable) stop_on :0, -- Stop indexing on block (0=disable) rewrite :false, -- Force rewrite the target replay range purge_queues :true, -- Clear rabbitmq queues before starting the indexer live_reader :false, -- Enable live reader live_only_mode :false, -- Only reads realtime data serially abi_scan_mode :true, fetch_block :true, -- Request full blocks from the state history plugin fetch_traces :true, -- Request traces from the state history plugin disable_reading :false, -- Completely disable block reading, for lagged queue processing disable_indexing :false, process_deltas :true, -- Read table deltas repair_mode :false }, features :{ streaming :{ -- Enable live streaming enable :false, traces :false, deltas :false }, tables :{ -- Tables to fetch proposals :true, accounts :true, voters :true, userres :false, delband :false }, index_deltas :true, -- Index common table deltas (see delta on definitions/mappings) index_transfer_memo :true, -- Index transfers memo index_all_deltas :true -- Index all table deltas }, prefetch :{ read :50, -- Stage 1 prefecth size block :100, -- Stage 2 prefecth size index :500 -- Stage 3 prefecth size }, experimental :{ PATCHED_SHIP :false } } Example Let's suppose that we gonna start Indexing the EOS Mainnet with: Locally exposed API 2 Readers 2 Deserializer Queues Live Streaming Enabled with Traces ABI scan already done The first step is to make a copy of the config file and rename it: chains/example.config.json to chains/eos.config.json . The next step is to edit the file as the following: { api : { chain_name : eos , server_addr : 127.0.0.1 , server_port : 7000, server_name : EOS MainNet , provider_name : Example Provider , provider_url : https://example.com , chain_logo_url : , enable_caching : true, cache_life : 1, limits : { get_actions : 1000, get_voters : 100 } }, settings : { preview : false, chain : eos , eosio_alias : eosio , parser : 2.0 , auto_stop : 30, index_version : v1 , debug : false, rate_monitoring : true, bp_logs : false, bp_monitoring : false }, blacklists : { actions : [], deltas : [] }, whitelists : { actions : [], deltas : [] }, scaling : { batch_size : 5000, queue_limit : 10000, readers : 2, ds_queues : 2, ds_threads : 1, ds_pool_size : 1, indexing_queues : 1, ad_idx_queues : 1, max_autoscale :4, auto_scale_trigger :20000 }, indexer : { start_on : 1, stop_on : 0, rewrite : false, purge_queues : true, live_reader : true, live_only_mode : false, abi_scan_mode : false, fetch_block : true, fetch_traces : true, disable_reading : false, disable_indexing : false, process_deltas : true, repair_mode : false }, features : { streaming : { enable : true, traces : true, deltas : false }, tables : { proposals : true, accounts : true, voters : true, userres : false, delband : false }, index_deltas : true, index_transfer_memo : true, index_all_deltas : true }, prefetch : { read : 50, block : 100, index : 500 }, experimental : { PATCHED_SHIP : false } } Tip For multiple chains, you should have one config file for each chain.","title":"Chain Configuration"},{"location":"chain/#detailed-description-of-the-chainsexampleconfigjson","text":"{ api :{ -- API configuration chain_name : EXAMPLE Chain , server_addr : 127.0.0.1 , server_port :7000, server_name : 127.0.0.1:7000 , provider_name : Example Provider , provider_url : https://example.com , chain_logo_url : , enable_caching :true, -- Set API cache cache_life :1, -- Define the cache life limits :{ -- Setting API response limits get_actions :1000, get_voters :100, get_links :1000, get_deltas :1000 }, access_log :false, enable_explorer :false }, settings :{ preview :false, - Preview mode - prints worker map and exit chain : eos , -- Chain named (The same used on ecosystem.config.js) eosio_alias : eosio , parser : 1.8 , -- Version of the parser to be used auto_stop :300, -- Automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) index_version : v1 , -- Set the index version debug :false, -- Set the debug mode rate_monitoring :true, bp_logs :false, -- Enable logs bp_monitoring :false, ipc_debug_rate :2000 }, blacklists :{ -- blacklist for actions and deltas actions :[ ], deltas :[ ] }, whitelists :{ -- whitelist for actions and deltas actions :[ ], deltas :[ ] }, scaling :{ -- Scalling options: batch_size :10000, -- Parallel reader batch size in blocks queue_limit :50000, -- Queue size limit on rabbitmq readers :1, -- Number of readers ds_queues :1, -- Number of deserializer queues ds_threads :1, -- Number of deserializer threads ds_pool_size :1, -- Deserializer pool size indexing_queues :1, -- Number of indexing queues ad_idx_queues :1, -- Multiplier for action indexing queues max_autoscale :4, -- Max number of readers to autoscale auto_scale_trigger :20000 -- Number of itens on queue to trigger autoscale }, indexer :{ -- Indexer configuration start_on :0, -- Start indexing on block (0=disable) stop_on :0, -- Stop indexing on block (0=disable) rewrite :false, -- Force rewrite the target replay range purge_queues :true, -- Clear rabbitmq queues before starting the indexer live_reader :false, -- Enable live reader live_only_mode :false, -- Only reads realtime data serially abi_scan_mode :true, fetch_block :true, -- Request full blocks from the state history plugin fetch_traces :true, -- Request traces from the state history plugin disable_reading :false, -- Completely disable block reading, for lagged queue processing disable_indexing :false, process_deltas :true, -- Read table deltas repair_mode :false }, features :{ streaming :{ -- Enable live streaming enable :false, traces :false, deltas :false }, tables :{ -- Tables to fetch proposals :true, accounts :true, voters :true, userres :false, delband :false }, index_deltas :true, -- Index common table deltas (see delta on definitions/mappings) index_transfer_memo :true, -- Index transfers memo index_all_deltas :true -- Index all table deltas }, prefetch :{ read :50, -- Stage 1 prefecth size block :100, -- Stage 2 prefecth size index :500 -- Stage 3 prefecth size }, experimental :{ PATCHED_SHIP :false } }","title":"Detailed description of the chains/example.config.json"},{"location":"chain/#example","text":"Let's suppose that we gonna start Indexing the EOS Mainnet with: Locally exposed API 2 Readers 2 Deserializer Queues Live Streaming Enabled with Traces ABI scan already done The first step is to make a copy of the config file and rename it: chains/example.config.json to chains/eos.config.json . The next step is to edit the file as the following: { api : { chain_name : eos , server_addr : 127.0.0.1 , server_port : 7000, server_name : EOS MainNet , provider_name : Example Provider , provider_url : https://example.com , chain_logo_url : , enable_caching : true, cache_life : 1, limits : { get_actions : 1000, get_voters : 100 } }, settings : { preview : false, chain : eos , eosio_alias : eosio , parser : 2.0 , auto_stop : 30, index_version : v1 , debug : false, rate_monitoring : true, bp_logs : false, bp_monitoring : false }, blacklists : { actions : [], deltas : [] }, whitelists : { actions : [], deltas : [] }, scaling : { batch_size : 5000, queue_limit : 10000, readers : 2, ds_queues : 2, ds_threads : 1, ds_pool_size : 1, indexing_queues : 1, ad_idx_queues : 1, max_autoscale :4, auto_scale_trigger :20000 }, indexer : { start_on : 1, stop_on : 0, rewrite : false, purge_queues : true, live_reader : true, live_only_mode : false, abi_scan_mode : false, fetch_block : true, fetch_traces : true, disable_reading : false, disable_indexing : false, process_deltas : true, repair_mode : false }, features : { streaming : { enable : true, traces : true, deltas : false }, tables : { proposals : true, accounts : true, voters : true, userres : false, delband : false }, index_deltas : true, index_transfer_memo : true, index_all_deltas : true }, prefetch : { read : 50, block : 100, index : 500 }, experimental : { PATCHED_SHIP : false } } Tip For multiple chains, you should have one config file for each chain.","title":"Example"},{"location":"connections/","text":"Detailed description of the connections.json { amqp :{ -- RabbitMQ parameters host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : my_user , pass : my_password , vhost : hyperion }, elasticsearch :{ -- Elasticsearch parameters host : 127.0.0.1:9200 , ingest_nodes :[ 127.0.0.1:9200 ], user : , pass : }, redis :{ -- Redis parameters host : 127.0.0.1 , port : 6379 }, chains :{ -- Chain Parameters eos :{ name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_HOST : 127.0.0.1 , -- Endpoint used by indexer to connect to the API. This is important when Indexer and API aren't on the same machine / instance. WS_ROUTER_PORT :7001 -- Port used by indexer to connect to API** } } } Example: In this example we have an connection.json file with: Local RabbitMQ user: admin pass: 123456 Local Elasticsearch no user no password Local Reddis Remote EOS Mainnet state history Remote WAX state history The first step is to make a copy of the config file and rename it: example-connections.json to connections.json . The next step is to edit the file as the following: { amqp : { host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : admin , pass : 123456 , vhost : hyperion }, elasticsearch : { host : 127.0.0.1:9200 , ingest_nodes : [ 127.0.0.1:9200 ], user : , pass : }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_PORT : 7001 }, sample : { name : Sample Mainnet , chain_id : 9473887b3cd1a897ce03ae5b6a865651747e2e152090f99c1d19d4adf73238fas , http : https://sample.io , ship : ws://192.168.0.1:8080 , WS_ROUTER_HOST : 127.0.0.1 , WS_ROUTER_PORT : 8034 } } }","title":"Connections"},{"location":"connections/#detailed-description-of-the-connectionsjson","text":"{ amqp :{ -- RabbitMQ parameters host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : my_user , pass : my_password , vhost : hyperion }, elasticsearch :{ -- Elasticsearch parameters host : 127.0.0.1:9200 , ingest_nodes :[ 127.0.0.1:9200 ], user : , pass : }, redis :{ -- Redis parameters host : 127.0.0.1 , port : 6379 }, chains :{ -- Chain Parameters eos :{ name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_HOST : 127.0.0.1 , -- Endpoint used by indexer to connect to the API. This is important when Indexer and API aren't on the same machine / instance. WS_ROUTER_PORT :7001 -- Port used by indexer to connect to API** } } }","title":"Detailed description of the connections.json"},{"location":"connections/#example","text":"In this example we have an connection.json file with: Local RabbitMQ user: admin pass: 123456 Local Elasticsearch no user no password Local Reddis Remote EOS Mainnet state history Remote WAX state history The first step is to make a copy of the config file and rename it: example-connections.json to connections.json . The next step is to edit the file as the following: { amqp : { host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : admin , pass : 123456 , vhost : hyperion }, elasticsearch : { host : 127.0.0.1:9200 , ingest_nodes : [ 127.0.0.1:9200 ], user : , pass : }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_PORT : 7001 }, sample : { name : Sample Mainnet , chain_id : 9473887b3cd1a897ce03ae5b6a865651747e2e152090f99c1d19d4adf73238fas , http : https://sample.io , ship : ws://192.168.0.1:8080 , WS_ROUTER_HOST : 127.0.0.1 , WS_ROUTER_PORT : 8034 } } }","title":"Example:"},{"location":"docker/","text":"Hyperion Docker Dependencies docker and docker-compose INSTALL Edit connections.json file and change http://host.docker.internal:8888 and ws://host.docker.internal:8080 for the nodeos address Change passwords in docker-compose.yml file Run docker-compose up Usage Kibana Access http://localhost:5601/ RabbitMQ Access http://127.0.0.1:15672/ Hyperion API Access http://127.0.0.1:7000/v2/history/get_actions or curl http://127.0.0.1:7000/v2/history/get_actions Troubleshooting If you're having problems accesing Kibana or using elasticsearch api, you could disable the xpack security on the docker-compose.yml setting it to false: xpack.security.enabled=false N\u00e3o incentivar a usar docker em produ\u00e7\u00e3o, s\u00f3 para desenvolvedor usar e fazer testes no ambiente local","title":"Docker"},{"location":"docker/#hyperion-docker","text":"","title":"Hyperion Docker"},{"location":"docker/#dependencies","text":"docker and docker-compose","title":"Dependencies"},{"location":"docker/#install","text":"Edit connections.json file and change http://host.docker.internal:8888 and ws://host.docker.internal:8080 for the nodeos address Change passwords in docker-compose.yml file Run docker-compose up","title":"INSTALL"},{"location":"docker/#usage","text":"","title":"Usage"},{"location":"docker/#kibana","text":"Access http://localhost:5601/","title":"Kibana"},{"location":"docker/#rabbitmq","text":"Access http://127.0.0.1:15672/","title":"RabbitMQ"},{"location":"docker/#hyperion-api","text":"Access http://127.0.0.1:7000/v2/history/get_actions or curl http://127.0.0.1:7000/v2/history/get_actions","title":"Hyperion API"},{"location":"docker/#troubleshooting","text":"If you're having problems accesing Kibana or using elasticsearch api, you could disable the xpack security on the docker-compose.yml setting it to false: xpack.security.enabled=false","title":"Troubleshooting"},{"location":"docker/#nao-incentivar-a-usar-docker-em-producao-so-para-desenvolvedor-usar-e-fazer-testes-no-ambiente-local","text":"","title":"N\u00e3o incentivar a usar docker em produ\u00e7\u00e3o, s\u00f3 para desenvolvedor usar e fazer testes no ambiente local"},{"location":"ecosystem/","text":"Detailed description of the ecosystem.config.js const {addApiServer, addIndexer} = require( ./definitions/ecosystem_settings ); module.exports = { apps: [ addIndexer('eos'), // Index chain name addApiServer('eos', 1) // API chain name, API threads number ] }; Multiple chains configuration To setup multiple Indexers and/or APIs, just add then inside the apps square brackets: const {addApiServer, addIndexer} = require( ./definitions/ecosystem_settings ); module.exports = { apps: [ addIndexer('eos'), addIndexer('wax'), addIndexer('bos'), addApiServer('eos', 1), addApiServer('bos', 1) ] };","title":"Ecosystem"},{"location":"ecosystem/#detailed-description-of-the-ecosystemconfigjs","text":"const {addApiServer, addIndexer} = require( ./definitions/ecosystem_settings ); module.exports = { apps: [ addIndexer('eos'), // Index chain name addApiServer('eos', 1) // API chain name, API threads number ] };","title":"Detailed description of the ecosystem.config.js"},{"location":"ecosystem/#multiple-chains-configuration","text":"To setup multiple Indexers and/or APIs, just add then inside the apps square brackets: const {addApiServer, addIndexer} = require( ./definitions/ecosystem_settings ); module.exports = { apps: [ addIndexer('eos'), addIndexer('wax'), addIndexer('bos'), addApiServer('eos', 1), addApiServer('bos', 1) ] };","title":"Multiple chains configuration"},{"location":"endpoint/","text":"Hyperion Open History Endpoint List Tip Check the endpoint status at https://bloks.io/hyperion EOS http://api.eossweden.org/v2/docs https://mainnet.eosn.io/v2/docs BOS http://api.bossweden.org/v2/docs https://bos.eosn.io/v2/docs https://bos.eosusa.news/v2/docs \ud83d\udea7 WAX https://api.waxsweden.org/v2/docs https://wax.eosusa.news/v2/docs https://wax.eosphere.io/v2/docs https://wax.pink.gg/v2/docs https://api-wax.maltablock.org/v2/docs http://api.blokcrafters.io/v2/doc https://hyperion.wax.eosdetroit.io TELOS https://mainnet.telosusa.io/v2/docs https://telos.eosphere.io/v2/docs https://api-telos-21zephyr.maltablock.org/v2/docs/ https://hyperion.telos.eosdetroit.io DAOBet mainnet https://daobet.eossweden.org/v2/docs https://daobet.eosusa.news/v2/docs/ INSTAR https://instar.eosusa.news/v2/docs WORBLI mainnet https://api.worblisweden.org/v2/docs MEETONE mainnet https://api.meetsweden.org/v2/docs Aikon/ORE Mainnet https://ore.eosusa.news/v2/docs/ Coffe api.coffe.io/v2/docs \ud83d\udea7 Kylin Testent https://kylin.eosusa.news/v2/docs https://kylin.eosn.io/v2/docs https://kylin.eossweden.org/v2/docs \ud83d\udea7 Jungle Testnet https://jungle.eosusa.news/v2/docs https://junglehistory.cryptolions.io/v2/docs https://jungle.eosn.io/v2/docs https://jungle.eossweden.org/v2/docs BOS Testnet https://tst.bossweden.org/v2/docs Telos Testnet https://testnet.telosusa.io/v2/docs WAX Testnet https://testnet.wax.pink.gg/v2/docs http://testnet.blokcrafters.io/v2/doc DAOBet Testnet https://daobet-test.eossweden.org/v2/docs https://test.daobet.eosusa.news/v2/docs/ Lynx Testnet https://tst.lynxsweden.org/v2/docs http://test.lynx.eosusa.news/v2/docs","title":"Endpoint List"},{"location":"endpoint/#hyperion-open-history-endpoint-list","text":"Tip Check the endpoint status at https://bloks.io/hyperion","title":"Hyperion Open History Endpoint List"},{"location":"endpoint/#eos","text":"http://api.eossweden.org/v2/docs https://mainnet.eosn.io/v2/docs","title":"EOS"},{"location":"endpoint/#bos","text":"http://api.bossweden.org/v2/docs https://bos.eosn.io/v2/docs https://bos.eosusa.news/v2/docs \ud83d\udea7","title":"BOS"},{"location":"endpoint/#wax","text":"https://api.waxsweden.org/v2/docs https://wax.eosusa.news/v2/docs https://wax.eosphere.io/v2/docs https://wax.pink.gg/v2/docs https://api-wax.maltablock.org/v2/docs http://api.blokcrafters.io/v2/doc https://hyperion.wax.eosdetroit.io","title":"WAX"},{"location":"endpoint/#telos","text":"https://mainnet.telosusa.io/v2/docs https://telos.eosphere.io/v2/docs https://api-telos-21zephyr.maltablock.org/v2/docs/ https://hyperion.telos.eosdetroit.io","title":"TELOS"},{"location":"endpoint/#daobet-mainnet","text":"https://daobet.eossweden.org/v2/docs https://daobet.eosusa.news/v2/docs/","title":"DAOBet mainnet"},{"location":"endpoint/#instar","text":"https://instar.eosusa.news/v2/docs","title":"INSTAR"},{"location":"endpoint/#worbli-mainnet","text":"https://api.worblisweden.org/v2/docs","title":"WORBLI mainnet"},{"location":"endpoint/#meetone-mainnet","text":"https://api.meetsweden.org/v2/docs","title":"MEETONE mainnet"},{"location":"endpoint/#aikonore-mainnet","text":"https://ore.eosusa.news/v2/docs/","title":"Aikon/ORE Mainnet"},{"location":"endpoint/#coffe","text":"api.coffe.io/v2/docs \ud83d\udea7","title":"Coffe"},{"location":"endpoint/#kylin-testent","text":"https://kylin.eosusa.news/v2/docs https://kylin.eosn.io/v2/docs https://kylin.eossweden.org/v2/docs \ud83d\udea7","title":"Kylin Testent"},{"location":"endpoint/#jungle-testnet","text":"https://jungle.eosusa.news/v2/docs https://junglehistory.cryptolions.io/v2/docs https://jungle.eosn.io/v2/docs https://jungle.eossweden.org/v2/docs","title":"Jungle Testnet"},{"location":"endpoint/#bos-testnet","text":"https://tst.bossweden.org/v2/docs","title":"BOS Testnet"},{"location":"endpoint/#telos-testnet","text":"https://testnet.telosusa.io/v2/docs","title":"Telos Testnet"},{"location":"endpoint/#wax-testnet","text":"https://testnet.wax.pink.gg/v2/docs http://testnet.blokcrafters.io/v2/doc","title":"WAX Testnet"},{"location":"endpoint/#daobet-testnet","text":"https://daobet-test.eossweden.org/v2/docs https://test.daobet.eosusa.news/v2/docs/","title":"DAOBet Testnet"},{"location":"endpoint/#lynx-testnet","text":"https://tst.lynxsweden.org/v2/docs http://test.lynx.eosusa.news/v2/docs","title":"Lynx Testnet"},{"location":"faq/","text":"","title":"FAQ"},{"location":"howtouse/","text":"How to use JavaScript client using https const https = require('https'); const HYPERION = 'https://api.eossweden.org/v2/history/get_actions'; //PEGAR ARGS let getActions = function (args) { let url = HYPERION + args; return new Promise(function (resolve) { https.get(url, (resp) = { let data = ''; // A chunk of data has been recieved. resp.on('data', (chunk) = { data += chunk; }); // The whole response has been received. Print out the result. resp.on('end', () = { resolve(JSON.parse(data)['actions']); }); }); }) }; Third party library https://github.com/eoscafe/hyperion-api","title":"Getting Started"},{"location":"howtouse/#how-to-use","text":"","title":"How to use"},{"location":"howtouse/#javascript-client-using-https","text":"const https = require('https'); const HYPERION = 'https://api.eossweden.org/v2/history/get_actions'; //PEGAR ARGS let getActions = function (args) { let url = HYPERION + args; return new Promise(function (resolve) { https.get(url, (resp) = { let data = ''; // A chunk of data has been recieved. resp.on('data', (chunk) = { data += chunk; }); // The whole response has been received. Print out the result. resp.on('end', () = { resolve(JSON.parse(data)['actions']); }); }); }) };","title":"JavaScript client using https"},{"location":"howtouse/#third-party-library","text":"https://github.com/eoscafe/hyperion-api","title":"Third party library"},{"location":"install/","text":"Getting Started Installation Dependencies This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.6.X RabbitMQ Redis Node.js v13 PM2 Nodeos 1.8+ w/ state_history_plugin and chain_api_plugin Note The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration. Elasticsearch Installation Info Follow the detailed installation instructions on the official elasticsearch documentation 1. Edit /etc/elasticsearch/elasticsearch.yml cluster.name: myCluster bootstrap.memory_lock: true Warning Setting bootstrap.memory_lock: true will try to use all the RAM configured for JVM (check next step) on startup. This could crash if you allocate more RAM tham available on the system. Setting mem_lock as false , might cause the JVM or shell session to exit if elasticsearch tries to allocate more memory than is available! After starting Elasticsearch, you can see whether this setting was applied successfully by checking the value of mlockall in the output from this request: GET _nodes?filter_path=**.mlockall 2. Edit /etc/elasticsearch/jvm.options # Set your heap size, avoid allocating more than 31GB, even if you have enought RAM. # Test on your specific machine by changing -Xmx32g in the following command: # java -Xmx32g -XX:+UseCompressedOops -XX:+PrintFlagsFinal Oops | grep Oops -Xms16g -Xmx16g 3. Allow memlock run sudo systemctl edit elasticsearch and add the following lines [Service] LimitMEMLOCK=infinity 4. Start elasticsearch and check the logs (verify if the memory lock was successful) sudo service elasticsearch start sudo less /var/log/elasticsearch/myCluster.log sudo systemctl enable elasticsearch 5. Test the REST API curl http://localhost:9200 { name : ip-172-31-5-121 , cluster_name : hyperion , cluster_uuid : .... , version : { number : 7.1.0 , build_flavor : default , build_type : deb , build_hash : 606a173 , build_date : 2019-05-16T00:43:15.323135Z , build_snapshot : false, lucene_version : 8.0.0 , minimum_wire_compatibility_version : 6.8.0 , minimum_index_compatibility_version : 6.0.0-beta1 }, tagline : You Know, for Search } The Default user and password is: user: elastic password: changeme You can change the password via the API, like this: curl -X POST localhost:9200/_security/user/elastic/_password?pretty -H 'Content-Type: application/json' -d' { password : new_password }' RabbitMQ Installation Info Follow the detailed installation instructions on the official RabbitMQ documentation 1. Enable the WebUI sudo rabbitmq-plugins enable rabbitmq_management 2. Add vhost sudo rabbitmqctl add_vhost /hyperion 2. Create a user and password sudo rabbitmqctl add_user {my_user} {my_password} 3. Set the user as administrator sudo rabbitmqctl set_user_tags {my_user} administrator 4. Set the user permissions to the vhost sudo rabbitmqctl set_permissions -p /hyperion {my_user} .* .* .* 5. Check access to the WebUI http://localhost:15672 Redis Installation 1. Install sudo apt install redis-server 2. Edit /etc/redis/redis.conf Note By default, redis binds to the localhost address. You need to edit the config file if you want to listen to other network. 3. Change supervised to systemd sudo systemctl restart redis.service NodeJS 1. Install the nodejs source curl -sL https://deb.nodesource.com/setup_13.x | sudo -E bash - 2. Install sudo apt-get install -y nodejs PM2 1. Install sudo npm install pm2@latest -g 2. Run sudo pm2 startup Info Follow the detailed installation instructions on the official documentation nodeos config.ini state-history-dir = state-history trace-history = true chain-state-history = true state-history-endpoint = 127.0.0.1:8080 plugin = eosio::state_history_plugin Hyperion 1. Clone Install packages git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install 2. Edit configs cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp :{ host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : my_user , pass : my_password , vhost : hyperion }, elasticsearch :{ host : 127.0.0.1:9200 , ingest_nodes :[ 127.0.0.1:9200 ], user : , pass : }, redis :{ host : 127.0.0.1 , port : 6379 }, chains :{ eos :{ name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_PORT :7001 } } } For more details, refer to the connections section ecosystem.config.js Reference module.exports = { apps: [ addIndexer('eos'), addApiServer('eos', 1) ] }; For more details, refer to the ecosystem section Setup Explicar as configura\u00e7\u00f5es iniciais. Modificar os example.ecosystems...etc Start and Stop We provide scripts to make simple the process of start and stop you Hyperion Indexer or API instance. But, you can also do it manually if you prefer. This section will cover both ways. Using run / stop script You can use run script to start the Indexer or the API. ./run.sh chain-indexer ./run.sh chain-api Examples: Start indexing EOS mainnet ./run.sh eos-indexer Start EOS API ./run.sh eos-api Remember that the chain name was previously defined on the Hyperion section . The stop script follows the same pattern of the run script: ./stop.sh chain-indexer ./stop.sh chain-api Example: Stop the EOS mainnet indexer ./stop.sh eos-indexer Note Stop script wont stop Hyperion Indexer immediately, it will first flush the queues. This operation could take some time. If you want to stop immediately, you need to run the \"Force stop command\" Commands Start indexing pm2 start --only chain-indexer --update-env pm2 logs chain-indexer Stop reading and wait for queues to flush pm2 trigger chain-indexer stop Force stop pm2 stop chain-indexer Starting the API node pm2 start --only chain-api --update-env pm2 logs chain-api API Reference API Reference: API section: v2 Example: OpenAPI Docs","title":"Install"},{"location":"install/#getting-started","text":"","title":"Getting Started"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#dependencies","text":"This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.6.X RabbitMQ Redis Node.js v13 PM2 Nodeos 1.8+ w/ state_history_plugin and chain_api_plugin Note The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration.","title":"Dependencies"},{"location":"install/#elasticsearch-installation","text":"Info Follow the detailed installation instructions on the official elasticsearch documentation","title":"Elasticsearch Installation"},{"location":"install/#1-edit-etcelasticsearchelasticsearchyml","text":"cluster.name: myCluster bootstrap.memory_lock: true Warning Setting bootstrap.memory_lock: true will try to use all the RAM configured for JVM (check next step) on startup. This could crash if you allocate more RAM tham available on the system. Setting mem_lock as false , might cause the JVM or shell session to exit if elasticsearch tries to allocate more memory than is available! After starting Elasticsearch, you can see whether this setting was applied successfully by checking the value of mlockall in the output from this request: GET _nodes?filter_path=**.mlockall","title":"1. Edit /etc/elasticsearch/elasticsearch.yml"},{"location":"install/#2-edit-etcelasticsearchjvmoptions","text":"# Set your heap size, avoid allocating more than 31GB, even if you have enought RAM. # Test on your specific machine by changing -Xmx32g in the following command: # java -Xmx32g -XX:+UseCompressedOops -XX:+PrintFlagsFinal Oops | grep Oops -Xms16g -Xmx16g","title":"2. Edit /etc/elasticsearch/jvm.options"},{"location":"install/#3-allow-memlock","text":"run sudo systemctl edit elasticsearch and add the following lines [Service] LimitMEMLOCK=infinity","title":"3. Allow memlock"},{"location":"install/#4-start-elasticsearch-and-check-the-logs-verify-if-the-memory-lock-was-successful","text":"sudo service elasticsearch start sudo less /var/log/elasticsearch/myCluster.log sudo systemctl enable elasticsearch","title":"4. Start elasticsearch and check the logs (verify if the memory lock was successful)"},{"location":"install/#5-test-the-rest-api","text":"curl http://localhost:9200 { name : ip-172-31-5-121 , cluster_name : hyperion , cluster_uuid : .... , version : { number : 7.1.0 , build_flavor : default , build_type : deb , build_hash : 606a173 , build_date : 2019-05-16T00:43:15.323135Z , build_snapshot : false, lucene_version : 8.0.0 , minimum_wire_compatibility_version : 6.8.0 , minimum_index_compatibility_version : 6.0.0-beta1 }, tagline : You Know, for Search } The Default user and password is: user: elastic password: changeme You can change the password via the API, like this: curl -X POST localhost:9200/_security/user/elastic/_password?pretty -H 'Content-Type: application/json' -d' { password : new_password }'","title":"5. Test the REST API"},{"location":"install/#rabbitmq-installation","text":"Info Follow the detailed installation instructions on the official RabbitMQ documentation","title":"RabbitMQ Installation"},{"location":"install/#1-enable-the-webui","text":"sudo rabbitmq-plugins enable rabbitmq_management","title":"1. Enable the WebUI"},{"location":"install/#2-add-vhost","text":"sudo rabbitmqctl add_vhost /hyperion","title":"2. Add vhost"},{"location":"install/#2-create-a-user-and-password","text":"sudo rabbitmqctl add_user {my_user} {my_password}","title":"2. Create a user and password"},{"location":"install/#3-set-the-user-as-administrator","text":"sudo rabbitmqctl set_user_tags {my_user} administrator","title":"3. Set the user as administrator"},{"location":"install/#4-set-the-user-permissions-to-the-vhost","text":"sudo rabbitmqctl set_permissions -p /hyperion {my_user} .* .* .*","title":"4. Set the user permissions to the vhost"},{"location":"install/#5-check-access-to-the-webui","text":"http://localhost:15672","title":"5. Check access to the WebUI"},{"location":"install/#redis-installation","text":"","title":"Redis Installation"},{"location":"install/#1-install","text":"sudo apt install redis-server","title":"1. Install"},{"location":"install/#2-edit-etcredisredisconf","text":"Note By default, redis binds to the localhost address. You need to edit the config file if you want to listen to other network.","title":"2. Edit /etc/redis/redis.conf"},{"location":"install/#3-change-supervised-to-systemd","text":"sudo systemctl restart redis.service","title":"3. Change supervised to systemd"},{"location":"install/#nodejs","text":"","title":"NodeJS"},{"location":"install/#1-install-the-nodejs-source","text":"curl -sL https://deb.nodesource.com/setup_13.x | sudo -E bash -","title":"1. Install the nodejs source"},{"location":"install/#2-install","text":"sudo apt-get install -y nodejs","title":"2. Install"},{"location":"install/#pm2","text":"","title":"PM2"},{"location":"install/#1-install_1","text":"sudo npm install pm2@latest -g","title":"1. Install"},{"location":"install/#2-run","text":"sudo pm2 startup Info Follow the detailed installation instructions on the official documentation","title":"2. Run"},{"location":"install/#nodeos-configini","text":"state-history-dir = state-history trace-history = true chain-state-history = true state-history-endpoint = 127.0.0.1:8080 plugin = eosio::state_history_plugin","title":"nodeos config.ini"},{"location":"install/#hyperion","text":"","title":"Hyperion"},{"location":"install/#1-clone-install-packages","text":"git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install","title":"1. Clone &amp; Install packages"},{"location":"install/#2-edit-configs","text":"cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp :{ host : 127.0.0.1:5672 , api : 127.0.0.1:15672 , user : my_user , pass : my_password , vhost : hyperion }, elasticsearch :{ host : 127.0.0.1:9200 , ingest_nodes :[ 127.0.0.1:9200 ], user : , pass : }, redis :{ host : 127.0.0.1 , port : 6379 }, chains :{ eos :{ name : EOS Mainnet , chain_id : aca376f206b8fc25a6ed44dbdc66547c36c6c33e3a119ffbeaef943642f0e906 , http : http://127.0.0.1:8888 , ship : ws://127.0.0.1:8080 , WS_ROUTER_PORT :7001 } } } For more details, refer to the connections section ecosystem.config.js Reference module.exports = { apps: [ addIndexer('eos'), addApiServer('eos', 1) ] }; For more details, refer to the ecosystem section","title":"2. Edit configs"},{"location":"install/#setup","text":"Explicar as configura\u00e7\u00f5es iniciais. Modificar os example.ecosystems...etc","title":"Setup"},{"location":"install/#start-and-stop","text":"We provide scripts to make simple the process of start and stop you Hyperion Indexer or API instance. But, you can also do it manually if you prefer. This section will cover both ways.","title":"Start and Stop"},{"location":"install/#using-run-stop-script","text":"You can use run script to start the Indexer or the API. ./run.sh chain-indexer ./run.sh chain-api Examples: Start indexing EOS mainnet ./run.sh eos-indexer Start EOS API ./run.sh eos-api Remember that the chain name was previously defined on the Hyperion section . The stop script follows the same pattern of the run script: ./stop.sh chain-indexer ./stop.sh chain-api Example: Stop the EOS mainnet indexer ./stop.sh eos-indexer Note Stop script wont stop Hyperion Indexer immediately, it will first flush the queues. This operation could take some time. If you want to stop immediately, you need to run the \"Force stop command\"","title":"Using run / stop script"},{"location":"install/#commands","text":"Start indexing pm2 start --only chain-indexer --update-env pm2 logs chain-indexer Stop reading and wait for queues to flush pm2 trigger chain-indexer stop Force stop pm2 stop chain-indexer Starting the API node pm2 start --only chain-api --update-env pm2 logs chain-api","title":"Commands"},{"location":"install/#api-reference","text":"API Reference: API section: v2 Example: OpenAPI Docs","title":"API Reference"},{"location":"kibana/","text":"The purpose here is to guide you through some basic steps using and configuring the Kibana. For more detailed information, please, refer to the official documentation . Running Kibana with systemd To configure Kibana to start automatically when the system boots up, run the following commands: sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable kibana.service Kibana can be started and stopped as follows: sudo systemctl start kibana.service sudo systemctl stop kibana.service These commands provide no feedback as to whether Kibana was started successfully or not. Log information can be accessed via journalctl -u kibana.service. Opening Kibana Open http://localhost:5601 and check if you can access Kibana. If Kibana asks for credentials, the default user and password is: user: elastic password: changeme If you can't access, check your credentials on your config file. Creating index pattern To create a new index pattern, go to Management Click on Index Patterns at the left menu Click on Create index pattern Enter desired index pattern and click on Next step Tip Index Pattern List: eos-abi-* eos-action-* eos-block-* eos-logs-* eos-delta-* Where eos is the name of the chain. Select a time filter, if there are any, and click on Create index pattern Index Management Discover","title":"Kibana"},{"location":"kibana/#running-kibana-with-systemd","text":"To configure Kibana to start automatically when the system boots up, run the following commands: sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable kibana.service Kibana can be started and stopped as follows: sudo systemctl start kibana.service sudo systemctl stop kibana.service These commands provide no feedback as to whether Kibana was started successfully or not. Log information can be accessed via journalctl -u kibana.service.","title":"Running Kibana with systemd"},{"location":"kibana/#opening-kibana","text":"Open http://localhost:5601 and check if you can access Kibana. If Kibana asks for credentials, the default user and password is: user: elastic password: changeme If you can't access, check your credentials on your config file.","title":"Opening Kibana"},{"location":"kibana/#creating-index-pattern","text":"To create a new index pattern, go to Management Click on Index Patterns at the left menu Click on Create index pattern Enter desired index pattern and click on Next step Tip Index Pattern List: eos-abi-* eos-action-* eos-block-* eos-logs-* eos-delta-* Where eos is the name of the chain. Select a time filter, if there are any, and click on Create index pattern","title":"Creating index pattern"},{"location":"kibana/#index-management","text":"","title":"Index Management"},{"location":"kibana/#discover","text":"","title":"Discover"},{"location":"quickstart/","text":"Tip The usage of this installation script is highly recommended for fresh installs. If already have dependencies installed, is indicated to update then manually before running the script. We provide an automated shell script that first install all dependencies and then configure Hyperion. All you need to do is to run it: ./install_infra.sh The script will ask you for some information: Enter rabbitmq user [hyperion]: Enter the desired rabbitmq user and hit enter. If you leave it in blank, the default user hyperion will be set. Then, the same for rabbitmq password: Enter rabbitmq password [123456]: And finally, it will ask if you want to create npm global folder: Do you want to create a directory for npm global installations [Y/n] : This is recommended. If you choose n , npm packages will be installed as root. Now, the script will do the work, this can take a while. Get a cup of coffee and relax. =) Info The install script may ask you for the admin password. This is needed to install the dependencies, please, provide it.","title":"Quick Start"},{"location":"rabbit/","text":"","title":"RabbitMQ"},{"location":"stream_client/","text":"Hyperion Stream Client Streaming Client for Hyperion History API (v3+) Usage We currently provide libraries for nodejs and prebuilt browser bundle npm package npm install @eosrio/hyperion-stream-client --save Import the client const HyperionSocketClient = require('@eosrio/hyperion-stream-client').default; Browser library script src= https:// ENDPOINT /stream-client.js /script Where ENDPOINT is the Hyperion API (e.g. https://wax.hyperion.eosrio.io ) For other usages the bundle is also available at dist/bundle.js 1. Connection Setup the endpoint that you want to fetch data from and the flow control mode: const client = new HyperionSocketClient(ENDPOINT, {async: false}); Example: const client = new HyperionSocketClient('https://example.com', {async: false}); https://example.com is the host, from where https://example.com/v2/history/... is served. Flow control mode: Async: true - The transmission will be asynchronous and you need an acknowledge function. Incoming data will be held on a local queue until ack is called. Async: false - The transmission will be synchronous. The acknowledge function is not needed. 2. Requests client.streamActions(request: StreamActionsRequest): void -- Request action stream client.streamDeltas(request: StreamDeltasRequest): void -- Request delta stream (contract rows) to ensure the client is connected, requests should be defined on the client.onConnect property, refer to examples below; 2.1 Action Stream - client.streamActions contract - contract account action - action name account - notified account name start_from - start reading on block or on a specific date: (0=disabled) read_until - stop reading on block (0=disable) or on a specific date (0=disabled) filters - actions filter (more details below) Notes - Block number can be either positive or negative - E.g.: -15000, 700 - In case of negative block number, it will be subtracted from the HEAD - Date format (ISO 8601) - e.g. 2020-01-01T00:00:00.000Z const HyperionSocketClient = require('@eosrio/hyperion-stream-client').default; const client = new HyperionSocketClient('http://localhost:7000', {async: true}); client.onConnect = () = { client.streamActions({ contract: 'eosio', action: 'voteproducer', account: '', start_from: '2020-03-15T00:00:00.000Z', read_until: 0, filters: [], }); } // see 3 for handling data client.onData = async (data, ack) = { console.log(data); // process incoming data, replace with your code ack(); // ACK when done } client.connect(() = { console.log('connected!'); }); 2.1.1 Act Data Filters You can setup filters to refine your stream. Filters should use fields following the Hyperion Action Data Structure, such as: act.data.producers (on eosio::voteproducer) @transfer.to (here the @ prefix is required since transfers have special mappings) please refer to the mapping definitions to know which data fields are available For example, to filter the stream for every transfer made to the eosio.ramfee account: client.streamActions({ contract: 'eosio.token', action: 'transfer', account: 'eosio', start_from: 0, read_until: 0, filters: [ {field: '@transfer.to', value: 'eosio.ramfee'} ], }); To refine even more your stream, you could add more filters. Remember that adding more filters will result in an AND operation, currently it's not possible to make OR operations with filters. 2.2 Delta Stream - client.streamDeltas code - contract account table - table name scope - table scope payer - ram payer start_from - start reading on block or on a specific date: (0=disabled) read_until - stop reading on block (0=disable) or on a specific date (0=disabled) Example: Referring to the same pattern as the action stream example above, one could also include a delta stream request client.streamDeltas({ code: 'eosio.token', table: '*', scope: '', payer: '', start_from: 0, read_until: 0, }); Note: Delta filters are planned to be implemented soon. 3. Handling Data Incoming data is handled via the client.onData callback data object is structured as follows: - type - action | delta - mode - live | history - content - Hyperion Data Structure (see action index template) client.onData = async (data, ack) = { console.log(data); // process incoming data, replace with your code ack(); // ACK when done } If you set async: false on the connection step, the ack must not be used: client.onData = async (data) = { //code here }","title":"Stream Client"},{"location":"stream_client/#hyperion-stream-client","text":"Streaming Client for Hyperion History API (v3+)","title":"Hyperion Stream Client"},{"location":"stream_client/#usage","text":"We currently provide libraries for nodejs and prebuilt browser bundle","title":"Usage"},{"location":"stream_client/#npm-package","text":"npm install @eosrio/hyperion-stream-client --save Import the client const HyperionSocketClient = require('@eosrio/hyperion-stream-client').default;","title":"npm package"},{"location":"stream_client/#browser-library","text":"script src= https:// ENDPOINT /stream-client.js /script Where ENDPOINT is the Hyperion API (e.g. https://wax.hyperion.eosrio.io ) For other usages the bundle is also available at dist/bundle.js","title":"Browser library"},{"location":"stream_client/#1-connection","text":"Setup the endpoint that you want to fetch data from and the flow control mode: const client = new HyperionSocketClient(ENDPOINT, {async: false}); Example: const client = new HyperionSocketClient('https://example.com', {async: false}); https://example.com is the host, from where https://example.com/v2/history/... is served. Flow control mode: Async: true - The transmission will be asynchronous and you need an acknowledge function. Incoming data will be held on a local queue until ack is called. Async: false - The transmission will be synchronous. The acknowledge function is not needed.","title":"1. Connection"},{"location":"stream_client/#2-requests","text":"client.streamActions(request: StreamActionsRequest): void -- Request action stream client.streamDeltas(request: StreamDeltasRequest): void -- Request delta stream (contract rows) to ensure the client is connected, requests should be defined on the client.onConnect property, refer to examples below;","title":"2. Requests"},{"location":"stream_client/#21-action-stream-clientstreamactions","text":"contract - contract account action - action name account - notified account name start_from - start reading on block or on a specific date: (0=disabled) read_until - stop reading on block (0=disable) or on a specific date (0=disabled) filters - actions filter (more details below) Notes - Block number can be either positive or negative - E.g.: -15000, 700 - In case of negative block number, it will be subtracted from the HEAD - Date format (ISO 8601) - e.g. 2020-01-01T00:00:00.000Z const HyperionSocketClient = require('@eosrio/hyperion-stream-client').default; const client = new HyperionSocketClient('http://localhost:7000', {async: true}); client.onConnect = () = { client.streamActions({ contract: 'eosio', action: 'voteproducer', account: '', start_from: '2020-03-15T00:00:00.000Z', read_until: 0, filters: [], }); } // see 3 for handling data client.onData = async (data, ack) = { console.log(data); // process incoming data, replace with your code ack(); // ACK when done } client.connect(() = { console.log('connected!'); });","title":"2.1 Action Stream - client.streamActions"},{"location":"stream_client/#211-act-data-filters","text":"You can setup filters to refine your stream. Filters should use fields following the Hyperion Action Data Structure, such as: act.data.producers (on eosio::voteproducer) @transfer.to (here the @ prefix is required since transfers have special mappings) please refer to the mapping definitions to know which data fields are available For example, to filter the stream for every transfer made to the eosio.ramfee account: client.streamActions({ contract: 'eosio.token', action: 'transfer', account: 'eosio', start_from: 0, read_until: 0, filters: [ {field: '@transfer.to', value: 'eosio.ramfee'} ], }); To refine even more your stream, you could add more filters. Remember that adding more filters will result in an AND operation, currently it's not possible to make OR operations with filters.","title":"2.1.1 Act Data Filters"},{"location":"stream_client/#22-delta-stream-clientstreamdeltas","text":"code - contract account table - table name scope - table scope payer - ram payer start_from - start reading on block or on a specific date: (0=disabled) read_until - stop reading on block (0=disable) or on a specific date (0=disabled) Example: Referring to the same pattern as the action stream example above, one could also include a delta stream request client.streamDeltas({ code: 'eosio.token', table: '*', scope: '', payer: '', start_from: 0, read_until: 0, }); Note: Delta filters are planned to be implemented soon.","title":"2.2 Delta Stream - client.streamDeltas"},{"location":"stream_client/#3-handling-data","text":"Incoming data is handled via the client.onData callback data object is structured as follows: - type - action | delta - mode - live | history - content - Hyperion Data Structure (see action index template) client.onData = async (data, ack) = { console.log(data); // process incoming data, replace with your code ack(); // ACK when done } If you set async: false on the connection step, the ack must not be used: client.onData = async (data) = { //code here }","title":"3. Handling Data"},{"location":"v1/","text":"API Reference: v1 /v1/history/get_actions POST Summary get actions Description legacy get actions query Request Body { account_name : string , pos : 0, offset : 0, filter : string , sort : desc , after : 2020-01-17T19:51:03.618Z , before : 2020-01-17T19:51:03.618Z , parent : 0 } Schema variable type description account_name string minLength: 1 maxLength: 12 notified account pos integer action position (pagination) offset integer limit of [n] actions per page filter string minLength: 3 code:name filter sort string sort direction Enum: [ desc, asc, 1, -1 ] after string($date-time) filter after specified date (ISO8601) before string($date-time) filter before specified date (ISO8601) parent integer minimum: 0 filter by parent global sequence Responses Code Description 200 Example curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_actions /v1/history/get_controlled_accounts POST Summary get controlled accounts by controlling accounts Description get controlled accounts by controlling accounts Request Body Required { controlling_account : string } Schema variable type description controlling_account string controlling account Responses Code Description 200 Example curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_controlled_accounts -d '{ controlling_account : eosio }' /v1/history/get_key_accounts POST Summary get accounts by public key Description get accounts by public key Request Body Required { public_key : string } Schema variable type description public_key public key public key Responses Code Description 200 Default Response Example curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_key_accounts -d '{ public_key : EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7 }' Code Description 200 /v1/history/get_transaction POST Summary get transaction by id Description get all actions belonging to the same transaction Request Body Required { id : string } Schema variable type description id string transaction id Responses Code Description 200 Default Response Example curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_transaction /v1/chain/get_block POST Summary Returns an object containing various details about a specific block on the blockchain. Description Returns an object containing various details about a specific block on the blockchain. Request Body { block_num_or_id : string } Schema block_num_or_id* - string - Provide a block number or a block id Responses Code Description 200 Default Response Example curl -X POST https://eos.hyperion.eosrio.io/v1/chain/get_block -d '{ block_num_or_id : 1000 }'","title":"v1 compatible"},{"location":"v1/#api-reference-v1","text":"","title":"API Reference: v1"},{"location":"v1/#v1historyget_actions","text":"","title":"/v1/history/get_actions"},{"location":"v1/#post","text":"","title":"POST"},{"location":"v1/#summary","text":"get actions","title":"Summary"},{"location":"v1/#description","text":"legacy get actions query","title":"Description"},{"location":"v1/#request-body","text":"{ account_name : string , pos : 0, offset : 0, filter : string , sort : desc , after : 2020-01-17T19:51:03.618Z , before : 2020-01-17T19:51:03.618Z , parent : 0 }","title":"Request Body"},{"location":"v1/#schema","text":"variable type description account_name string minLength: 1 maxLength: 12 notified account pos integer action position (pagination) offset integer limit of [n] actions per page filter string minLength: 3 code:name filter sort string sort direction Enum: [ desc, asc, 1, -1 ] after string($date-time) filter after specified date (ISO8601) before string($date-time) filter before specified date (ISO8601) parent integer minimum: 0 filter by parent global sequence","title":"Schema"},{"location":"v1/#responses","text":"Code Description 200","title":"Responses"},{"location":"v1/#example","text":"curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_actions","title":"Example"},{"location":"v1/#v1historyget_controlled_accounts","text":"","title":"/v1/history/get_controlled_accounts"},{"location":"v1/#post_1","text":"","title":"POST"},{"location":"v1/#summary_1","text":"get controlled accounts by controlling accounts","title":"Summary"},{"location":"v1/#description_1","text":"get controlled accounts by controlling accounts","title":"Description"},{"location":"v1/#request-body-required","text":"{ controlling_account : string }","title":"Request Body Required"},{"location":"v1/#schema_1","text":"variable type description controlling_account string controlling account","title":"Schema"},{"location":"v1/#responses_1","text":"Code Description 200","title":"Responses"},{"location":"v1/#example_1","text":"curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_controlled_accounts -d '{ controlling_account : eosio }'","title":"Example"},{"location":"v1/#v1historyget_key_accounts","text":"","title":"/v1/history/get_key_accounts"},{"location":"v1/#post_2","text":"","title":"POST"},{"location":"v1/#summary_2","text":"get accounts by public key","title":"Summary"},{"location":"v1/#description_2","text":"get accounts by public key","title":"Description"},{"location":"v1/#request-body-required_1","text":"{ public_key : string }","title":"Request Body Required"},{"location":"v1/#schema_2","text":"variable type description public_key public key public key","title":"Schema"},{"location":"v1/#responses_2","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v1/#example_2","text":"curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_key_accounts -d '{ public_key : EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7 }' Code Description 200","title":"Example"},{"location":"v1/#v1historyget_transaction","text":"","title":"/v1/history/get_transaction"},{"location":"v1/#post_3","text":"","title":"POST"},{"location":"v1/#summary_3","text":"get transaction by id","title":"Summary"},{"location":"v1/#description_3","text":"get all actions belonging to the same transaction","title":"Description"},{"location":"v1/#request-body-required_2","text":"{ id : string }","title":"Request Body Required"},{"location":"v1/#schema_3","text":"variable type description id string transaction id","title":"Schema"},{"location":"v1/#responses_3","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v1/#example_3","text":"curl -X POST https://eos.hyperion.eosrio.io/v1/history/get_transaction","title":"Example"},{"location":"v1/#v1chainget_block","text":"","title":"/v1/chain/get_block"},{"location":"v1/#post_4","text":"","title":"POST"},{"location":"v1/#summary_4","text":"Returns an object containing various details about a specific block on the blockchain.","title":"Summary"},{"location":"v1/#description_4","text":"Returns an object containing various details about a specific block on the blockchain.","title":"Description"},{"location":"v1/#request-body_1","text":"{ block_num_or_id : string }","title":"Request Body"},{"location":"v1/#schema_4","text":"block_num_or_id* - string - Provide a block number or a block id","title":"Schema"},{"location":"v1/#responses_4","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v1/#example_4","text":"curl -X POST https://eos.hyperion.eosrio.io/v1/chain/get_block -d '{ block_num_or_id : 1000 }'","title":"Example"},{"location":"v2/","text":"API Reference: v2 Tip For more details and live testing, check our WAX swagger /v2/history/get_abi_snapshot GET Summary fetch abi at specific block Description fetch contract abi at specific block Parameters Name Located in Description Required Schema contract query contract account Yes string block query target block No integer fetch query should fetch the ABI No boolean Responses Code Description 200 Default Response /v2/history/get_actions GET Summary get root actions Description get actions based on notified account. this endpoint also accepts generic filters based on indexed fields (e.g. act.authorization.actor=eosio or act.name=delegatebw), if included they will be combined with a AND operator Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query notified account No string track query total results to track (count) [number or true] No string filter query code:name filter No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer sort query sort direction No string after query filter after specified date (ISO8601) No string before query filter before specified date (ISO8601) No string simple query simplified output mode No boolean Responses Code Description 200 /v2/history/get_blocks GET Summary get block range Description get block range Request Body N/A Schema N/A Parameters Name Located in Description Required Schema from query starting block No integer to query last block No integer Responses Code Description 200 Default Response Examples Get all blocks curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks Get all blocks starting from block 1000 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks?from=1000 Get blocks from 10 to 15 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks?from=10 to=15 /v2/history/get_created_accounts GET Summary get created accounts Description get all accounts created by one creator Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query creator account No string Responses Code Description 200 Examples curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_created_accounts?account=eosio /v2/history/get_creator GET Summary get account creator Description get account creator Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query created account No string Responses Code Description 200 Example curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_creator?account=eosriobrazil /v2/history/get_deltas GET Summary get state deltas Description get state deltas Request Body N/A Schema N/A Parameters Name Located in Description Required Schema code query contract account No string scope query table scope No string table query table name No string payer query payer account No string Responses Code Description 200 Default Response Examples Get all deltas from eosio.token contract curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_deltas?code=eosio.token Get all deltas from the table accounts of the eosio.token contract curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_deltas?code=eosio.token table=accounts /v2/history/get_transacted_accounts GET Summary get interactions based on transfers Description get all account that interacted with the source account provided Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query source account Yes string symbol query token symbol No string contract query token contract No string direction query search direction Yes string min query minimum value No number max query maximum value No number limit query query limit No number after query filter after specified date (ISO8601) or block number No string before query filter before specified date (ISO8601) or block number No string Responses Code Description 200 Default Response Example /v2/history/get_transaction GET Summary get transaction by id Description get all actions belonging to the same transaction Request Body N/A Schema N/A Parameters Name Located in Description Required Schema id query transaction id Yes string Example curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transaction?id=eec44c2ab2c2330e88fdacd3cd4c63838adb60da679ff12f299a4341fd036658 Responses Code Description 200 Default Response /v2/history/get_transfers GET Summary get token transfers Description get token transfers utilizing the eosio.token standard Request Body N/A Schema N/A Parameters Name Located in Description Required Schema from query source account No string to query destination account No string symbol query token symbol No string contract query token contract No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer after query filter after specified date (ISO8601) No dateTime before query filter before specified date (ISO8601) No dateTime Responses Code Description 200 Example Get all transfers from eosriobrazil account curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil Get all transfer from eosriobrazil account to eosio.ramfee account curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil to=eosio.ramfee Get all transfer from eosriobrazil account to eosio.ramfee account after November 2019 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil to=eosio.ramfee after=2019-11-01T00:00:00.000Z /v2/state/get_account GET Summary get account summary Description get account data Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query account name No string Responses Code Description 200 Default Response Example curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_account?account=eosio /v2/state/get_key_accounts GET Summary get accounts by public key Description get accounts by public key Request Body N/A Schema N/A Parameters Name Located in Description Required Schema public_key query public key Yes string Responses Code Description 200 Example curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_key_accounts?public_key=EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7 /v2/state/get_key_accounts POST Summary get accounts by public key Description get accounts by public key Request Body { public_key : string } Schema variable type description public_key public key public key Responses Code Description 200 Example curl -X POST https://eos.hyperion.eosrio.io/v2/state/get_key_accounts -d '{ public_key : EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7 }' /v2/state/get_proposals GET Summary get proposals Description get proposals Parameters Name Located in Description Required Schema proposer query filter by proposer No string proposal query filter by proposal name No string account query filter by either requested or provided account No string requested query filter by requested account No string provided query filter by provided account No string executed query filter by execution status No boolean track query total results to track (count) [number or true] No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer Responses Code Description 200 Default Response /v2/state/get_tokens GET Summary get tokens from account Description get tokens from account Request Body N/A Schema N/A Parameters Name Located in Description Required Schema account query account Yes string Responses Code Description 200 Example curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_tokens?account=eosriobrazil /v2/state/get_voters GET Summary get voters Description get voters Request Body N/A Schema N/A Parameters Name Located in Description Required Schema producer query filter by voted producer (comma separated) No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer Responses Code Description 200 Default Response Example Get all eosriobrazil voters curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_voters?producer=eosriobrazil Get only the first 3 responses curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_voters?producer=eosriobrazil limit=3 /v2/health GET Summary: API Service Health Report Responses Code Description 200 Default Response /stream-client.js GET Responses Code Description 200 default response","title":"v2"},{"location":"v2/#api-reference-v2","text":"Tip For more details and live testing, check our WAX swagger","title":"API Reference: v2"},{"location":"v2/#v2historyget_abi_snapshot","text":"","title":"/v2/history/get_abi_snapshot"},{"location":"v2/#get","text":"","title":"GET"},{"location":"v2/#summary","text":"fetch abi at specific block","title":"Summary"},{"location":"v2/#description","text":"fetch contract abi at specific block","title":"Description"},{"location":"v2/#parameters","text":"Name Located in Description Required Schema contract query contract account Yes string block query target block No integer fetch query should fetch the ABI No boolean","title":"Parameters"},{"location":"v2/#responses","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#v2historyget_actions","text":"","title":"/v2/history/get_actions"},{"location":"v2/#get_1","text":"","title":"GET"},{"location":"v2/#summary_1","text":"get root actions","title":"Summary"},{"location":"v2/#description_1","text":"get actions based on notified account. this endpoint also accepts generic filters based on indexed fields (e.g. act.authorization.actor=eosio or act.name=delegatebw), if included they will be combined with a AND operator","title":"Description"},{"location":"v2/#request-body","text":"N/A","title":"Request Body"},{"location":"v2/#schema","text":"N/A","title":"Schema"},{"location":"v2/#parameters_1","text":"Name Located in Description Required Schema account query notified account No string track query total results to track (count) [number or true] No string filter query code:name filter No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer sort query sort direction No string after query filter after specified date (ISO8601) No string before query filter before specified date (ISO8601) No string simple query simplified output mode No boolean","title":"Parameters"},{"location":"v2/#responses_1","text":"Code Description 200","title":"Responses"},{"location":"v2/#v2historyget_blocks","text":"","title":"/v2/history/get_blocks"},{"location":"v2/#get_2","text":"","title":"GET"},{"location":"v2/#summary_2","text":"get block range","title":"Summary"},{"location":"v2/#description_2","text":"get block range","title":"Description"},{"location":"v2/#request-body_1","text":"N/A","title":"Request Body"},{"location":"v2/#schema_1","text":"N/A","title":"Schema"},{"location":"v2/#parameters_2","text":"Name Located in Description Required Schema from query starting block No integer to query last block No integer","title":"Parameters"},{"location":"v2/#responses_2","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#examples","text":"Get all blocks curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks Get all blocks starting from block 1000 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks?from=1000 Get blocks from 10 to 15 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_blocks?from=10 to=15","title":"Examples"},{"location":"v2/#v2historyget_created_accounts","text":"","title":"/v2/history/get_created_accounts"},{"location":"v2/#get_3","text":"","title":"GET"},{"location":"v2/#summary_3","text":"get created accounts","title":"Summary"},{"location":"v2/#description_3","text":"get all accounts created by one creator","title":"Description"},{"location":"v2/#request-body_2","text":"N/A","title":"Request Body"},{"location":"v2/#schema_2","text":"N/A","title":"Schema"},{"location":"v2/#parameters_3","text":"Name Located in Description Required Schema account query creator account No string","title":"Parameters"},{"location":"v2/#responses_3","text":"Code Description 200","title":"Responses"},{"location":"v2/#examples_1","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_created_accounts?account=eosio","title":"Examples"},{"location":"v2/#v2historyget_creator","text":"","title":"/v2/history/get_creator"},{"location":"v2/#get_4","text":"","title":"GET"},{"location":"v2/#summary_4","text":"get account creator","title":"Summary"},{"location":"v2/#description_4","text":"get account creator","title":"Description"},{"location":"v2/#request-body_3","text":"N/A","title":"Request Body"},{"location":"v2/#schema_3","text":"N/A","title":"Schema"},{"location":"v2/#parameters_4","text":"Name Located in Description Required Schema account query created account No string","title":"Parameters"},{"location":"v2/#responses_4","text":"Code Description 200","title":"Responses"},{"location":"v2/#example","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_creator?account=eosriobrazil","title":"Example"},{"location":"v2/#v2historyget_deltas","text":"","title":"/v2/history/get_deltas"},{"location":"v2/#get_5","text":"","title":"GET"},{"location":"v2/#summary_5","text":"get state deltas","title":"Summary"},{"location":"v2/#description_5","text":"get state deltas","title":"Description"},{"location":"v2/#request-body_4","text":"N/A","title":"Request Body"},{"location":"v2/#schema_4","text":"N/A","title":"Schema"},{"location":"v2/#parameters_5","text":"Name Located in Description Required Schema code query contract account No string scope query table scope No string table query table name No string payer query payer account No string","title":"Parameters"},{"location":"v2/#responses_5","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#examples_2","text":"Get all deltas from eosio.token contract curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_deltas?code=eosio.token Get all deltas from the table accounts of the eosio.token contract curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_deltas?code=eosio.token table=accounts","title":"Examples"},{"location":"v2/#v2historyget_transacted_accounts","text":"","title":"/v2/history/get_transacted_accounts"},{"location":"v2/#get_6","text":"","title":"GET"},{"location":"v2/#summary_6","text":"get interactions based on transfers","title":"Summary"},{"location":"v2/#description_6","text":"get all account that interacted with the source account provided","title":"Description"},{"location":"v2/#request-body_5","text":"N/A","title":"Request Body"},{"location":"v2/#schema_5","text":"N/A","title":"Schema"},{"location":"v2/#parameters_6","text":"Name Located in Description Required Schema account query source account Yes string symbol query token symbol No string contract query token contract No string direction query search direction Yes string min query minimum value No number max query maximum value No number limit query query limit No number after query filter after specified date (ISO8601) or block number No string before query filter before specified date (ISO8601) or block number No string","title":"Parameters"},{"location":"v2/#responses_6","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#example_1","text":"","title":"Example"},{"location":"v2/#v2historyget_transaction","text":"","title":"/v2/history/get_transaction"},{"location":"v2/#get_7","text":"","title":"GET"},{"location":"v2/#summary_7","text":"get transaction by id","title":"Summary"},{"location":"v2/#description_7","text":"get all actions belonging to the same transaction","title":"Description"},{"location":"v2/#request-body_6","text":"N/A","title":"Request Body"},{"location":"v2/#schema_6","text":"N/A","title":"Schema"},{"location":"v2/#parameters_7","text":"Name Located in Description Required Schema id query transaction id Yes string","title":"Parameters"},{"location":"v2/#example_2","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transaction?id=eec44c2ab2c2330e88fdacd3cd4c63838adb60da679ff12f299a4341fd036658","title":"Example"},{"location":"v2/#responses_7","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#v2historyget_transfers","text":"","title":"/v2/history/get_transfers"},{"location":"v2/#get_8","text":"","title":"GET"},{"location":"v2/#summary_8","text":"get token transfers","title":"Summary"},{"location":"v2/#description_8","text":"get token transfers utilizing the eosio.token standard","title":"Description"},{"location":"v2/#request-body_7","text":"N/A","title":"Request Body"},{"location":"v2/#schema_7","text":"N/A","title":"Schema"},{"location":"v2/#parameters_8","text":"Name Located in Description Required Schema from query source account No string to query destination account No string symbol query token symbol No string contract query token contract No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer after query filter after specified date (ISO8601) No dateTime before query filter before specified date (ISO8601) No dateTime","title":"Parameters"},{"location":"v2/#responses_8","text":"Code Description 200","title":"Responses"},{"location":"v2/#example_3","text":"Get all transfers from eosriobrazil account curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil Get all transfer from eosriobrazil account to eosio.ramfee account curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil to=eosio.ramfee Get all transfer from eosriobrazil account to eosio.ramfee account after November 2019 curl -X GET https://eos.hyperion.eosrio.io/v2/history/get_transfers?from=eosriobrazil to=eosio.ramfee after=2019-11-01T00:00:00.000Z","title":"Example"},{"location":"v2/#v2stateget_account","text":"","title":"/v2/state/get_account"},{"location":"v2/#get_9","text":"","title":"GET"},{"location":"v2/#summary_9","text":"get account summary","title":"Summary"},{"location":"v2/#description_9","text":"get account data","title":"Description"},{"location":"v2/#request-body_8","text":"N/A","title":"Request Body"},{"location":"v2/#schema_8","text":"N/A","title":"Schema"},{"location":"v2/#parameters_9","text":"Name Located in Description Required Schema account query account name No string","title":"Parameters"},{"location":"v2/#responses_9","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#example_4","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_account?account=eosio","title":"Example"},{"location":"v2/#v2stateget_key_accounts","text":"","title":"/v2/state/get_key_accounts"},{"location":"v2/#get_10","text":"","title":"GET"},{"location":"v2/#summary_10","text":"get accounts by public key","title":"Summary"},{"location":"v2/#description_10","text":"get accounts by public key","title":"Description"},{"location":"v2/#request-body_9","text":"N/A","title":"Request Body"},{"location":"v2/#schema_9","text":"N/A","title":"Schema"},{"location":"v2/#parameters_10","text":"Name Located in Description Required Schema public_key query public key Yes string","title":"Parameters"},{"location":"v2/#responses_10","text":"Code Description 200","title":"Responses"},{"location":"v2/#example_5","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_key_accounts?public_key=EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7","title":"Example"},{"location":"v2/#v2stateget_key_accounts_1","text":"","title":"/v2/state/get_key_accounts"},{"location":"v2/#post","text":"","title":"POST"},{"location":"v2/#summary_11","text":"get accounts by public key","title":"Summary"},{"location":"v2/#description_11","text":"get accounts by public key","title":"Description"},{"location":"v2/#request-body_10","text":"{ public_key : string }","title":"Request Body"},{"location":"v2/#schema_10","text":"variable type description public_key public key public key","title":"Schema"},{"location":"v2/#responses_11","text":"Code Description 200","title":"Responses"},{"location":"v2/#example_6","text":"curl -X POST https://eos.hyperion.eosrio.io/v2/state/get_key_accounts -d '{ public_key : EOS8fDDZm7ommT5XBf9MPYkRioXX6GeCUeSNkTpimdwKon5bNAVm7 }'","title":"Example"},{"location":"v2/#v2stateget_proposals","text":"","title":"/v2/state/get_proposals"},{"location":"v2/#get_11","text":"","title":"GET"},{"location":"v2/#summary_12","text":"get proposals","title":"Summary"},{"location":"v2/#description_12","text":"get proposals","title":"Description"},{"location":"v2/#parameters_11","text":"Name Located in Description Required Schema proposer query filter by proposer No string proposal query filter by proposal name No string account query filter by either requested or provided account No string requested query filter by requested account No string provided query filter by provided account No string executed query filter by execution status No boolean track query total results to track (count) [number or true] No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer","title":"Parameters"},{"location":"v2/#responses_12","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#v2stateget_tokens","text":"","title":"/v2/state/get_tokens"},{"location":"v2/#get_12","text":"","title":"GET"},{"location":"v2/#summary_13","text":"get tokens from account","title":"Summary"},{"location":"v2/#description_13","text":"get tokens from account","title":"Description"},{"location":"v2/#request-body_11","text":"N/A","title":"Request Body"},{"location":"v2/#schema_11","text":"N/A","title":"Schema"},{"location":"v2/#parameters_12","text":"Name Located in Description Required Schema account query account Yes string","title":"Parameters"},{"location":"v2/#responses_13","text":"Code Description 200","title":"Responses"},{"location":"v2/#example_7","text":"curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_tokens?account=eosriobrazil","title":"Example"},{"location":"v2/#v2stateget_voters","text":"","title":"/v2/state/get_voters"},{"location":"v2/#get_13","text":"","title":"GET"},{"location":"v2/#summary_14","text":"get voters","title":"Summary"},{"location":"v2/#description_14","text":"get voters","title":"Description"},{"location":"v2/#request-body_12","text":"N/A","title":"Request Body"},{"location":"v2/#schema_12","text":"N/A","title":"Schema"},{"location":"v2/#parameters_13","text":"Name Located in Description Required Schema producer query filter by voted producer (comma separated) No string skip query skip [n] actions (pagination) No integer limit query limit of [n] actions per page No integer","title":"Parameters"},{"location":"v2/#responses_14","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#example_8","text":"Get all eosriobrazil voters curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_voters?producer=eosriobrazil Get only the first 3 responses curl -X GET https://eos.hyperion.eosrio.io/v2/state/get_voters?producer=eosriobrazil limit=3","title":"Example"},{"location":"v2/#v2health","text":"","title":"/v2/health"},{"location":"v2/#get_14","text":"","title":"GET"},{"location":"v2/#summary_15","text":"API Service Health Report","title":"Summary:"},{"location":"v2/#responses_15","text":"Code Description 200 Default Response","title":"Responses"},{"location":"v2/#stream-clientjs","text":"","title":"/stream-client.js"},{"location":"v2/#get_15","text":"","title":"GET"},{"location":"v2/#responses_16","text":"Code Description 200 default response","title":"Responses"}]}